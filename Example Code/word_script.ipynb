{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "danish-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advance-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from files\n",
    "headlines = pd.read_csv(r\"C:\\Users\\Neal\\OneDrive - University of Iowa\\Spring 2021\\GEOG 3760\\Content Analysis\\new_list.csv\")\n",
    "article_bodies = open(r\"C:\\Users\\Neal\\OneDrive - University of Iowa\\Spring 2021\\GEOG 3760\\Content Analysis\\text_file1.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suburban-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of headline terms\n",
    "stringtext = \"\"\n",
    "for i in headlines[\"Headline\"]:\n",
    "    stringtext += str(i+\" \").lower()\n",
    "headlines_clear = stringtext.translate(str.maketrans('', '', string.punctuation))\n",
    "headlines_wordlist = headlines_clear.split()\n",
    "headlines_wordfreq = {}\n",
    "for w in headlines_wordlist:\n",
    "    headlines_wordfreq[w] = headlines_wordlist.count(w)\n",
    "headlines_sorted = dict(sorted(headlines_wordfreq.items(), key = lambda item: item[1],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count of term in headlines\n",
    "headlines_wordfreq['tornado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart for word frequency\n",
    "df_headlines = pd.DataFrame.from_dict(headlines_sorted,orient='index')\n",
    "df_headlines.columns = df_headlines.columns.map(str)\n",
    "df = df_headlines[df_headlines.index.str.len()>4]\n",
    "\n",
    "plt.bar(df.index[:20],df[\"0\"][:20])\n",
    "plt.ylabel('Word Count')\n",
    "plt.xlabel('Word')\n",
    "plt.xticks(df.index[:20], df.index[:20], rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find keyword in article bodies and display immediate surrounding text\n",
    "keyword = 'happy'\n",
    "articles_split = re.split(\"News;\",article_bodies)\n",
    "for article in articles_split:\n",
    "    if keyword in article:\n",
    "        index_val = article.find(keyword)\n",
    "        sentence = \"\"\n",
    "        for letter in range(index_val-30, index_val+45):\n",
    "            try: sentence += article[letter]\n",
    "            except: continue\n",
    "        print(str(sentence),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full sentences containing terms of interest\n",
    "article_search = [text.split('. ') for text in article_bodies.split('. ') if 'sad' in text]\n",
    "for line in article_search:\n",
    "    print(re.sub(\"[^0-9A-Za-z ]\", \"\", str(line)),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "velvet-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of temrs from full articles\n",
    "articles_clear = article_bodies.translate(str.maketrans('', '', string.punctuation))\n",
    "# articles_clear = re.sub(\"[^0-9A-Za-z]\", \"\", article_bodies)\n",
    "# articles_clear = re.sub(\"([A-Z+]+)\",\"\",articles_Clear)\n",
    "articles_split = articles_clear.split()\n",
    "articles_wordfreq = {}\n",
    "for w in articles_split:\n",
    "    articles_wordfreq[w] = articles_split.count(w)\n",
    "articles_sorted = dict(sorted(articles_wordfreq.items(), key = lambda item: item[1],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = ['there','going','about','right','their','because','still','other','think',\n",
    "                'really','those','could','after','UNIDENTIFIED','these','thats','VIDEO',\n",
    "                'where','COOPER','today','through','trying','youre','theyre','theres',\n",
    "                'which','would','Thats','BEGIN','There','around','being']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart for word frequency\n",
    "copy1 = articles_sorted.copy()\n",
    "copy2 = copy1.copy()\n",
    "for key in copy2.keys():\n",
    "    if key in common_words:\n",
    "        copy1.pop(key)\n",
    "df_articles = pd.DataFrame.from_dict(copy1,orient='index')\n",
    "df_articles.columns = df_articles.columns.map(str)\n",
    "df = df_articles[df_articles.index.str.len()>4]\n",
    "\n",
    "plt.bar(df.index[:20],df[\"0\"][:20])\n",
    "plt.ylabel('Word Count')\n",
    "plt.xlabel('Word')\n",
    "plt.xticks(df.index[:20], df.index[:20], rotation='vertical')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
